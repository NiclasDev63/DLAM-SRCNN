{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import SRCNN\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SRCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57281"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = sum(p.numel() for p in model.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5184\n",
      "conv1.weight torch.Size([64, 1, 9, 9])\n",
      "64\n",
      "conv1.bias torch.Size([64])\n",
      "51200\n",
      "conv2.weight torch.Size([32, 64, 5, 5])\n",
      "32\n",
      "conv2.bias torch.Size([32])\n",
      "800\n",
      "conv3.weight torch.Size([1, 32, 5, 5])\n",
      "1\n",
      "conv3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[1].numel())\n",
    "    print(param[0], param[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GradientVariance(nn.Module):\n",
    "    \"\"\"Class for calculating GV loss between to RGB images\n",
    "       :parameter\n",
    "       patch_size : int, scalar, size of the patches extracted from the gt and predicted images\n",
    "       cpu : bool,  whether to run calculation on cpu or gpu\n",
    "        \"\"\"\n",
    "    def __init__(self, patch_size, cpu=False):\n",
    "        super(GradientVariance, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        # Sobel kernel for the gradient map calculation\n",
    "        self.kernel_x = torch.FloatTensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).unsqueeze(0).unsqueeze(0)\n",
    "        self.kernel_y = torch.FloatTensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]).unsqueeze(0).unsqueeze(0)\n",
    "        if not cpu:\n",
    "            self.kernel_x = self.kernel_x.cuda()\n",
    "            self.kernel_y = self.kernel_y.cuda()\n",
    "        # operation for unfolding image into non overlapping patches\n",
    "        self.unfold = torch.nn.Unfold(kernel_size=(self.patch_size, self.patch_size), stride=self.patch_size)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # converting RGB image to grayscale\n",
    "        gray_output = 0.2989 * output[:, 0:1, :, :] + 0.5870 * output[:, 1:2, :, :] + 0.1140 * output[:, 2:, :, :]\n",
    "        gray_target = 0.2989 * target[:, 0:1, :, :] + 0.5870 * target[:, 1:2, :, :] + 0.1140 * target[:, 2:, :, :]\n",
    "\n",
    "        # calculation of the gradient maps of x and y directions\n",
    "        gx_target = F.conv2d(gray_target, self.kernel_x, stride=1, padding=1)\n",
    "        gy_target = F.conv2d(gray_target, self.kernel_y, stride=1, padding=1)\n",
    "        gx_output = F.conv2d(gray_output, self.kernel_x, stride=1, padding=1)\n",
    "        gy_output = F.conv2d(gray_output, self.kernel_y, stride=1, padding=1)\n",
    "\n",
    "        # unfolding image to patches\n",
    "        gx_target_patches = self.unfold(gx_target)\n",
    "        gy_target_patches = self.unfold(gy_target)\n",
    "        gx_output_patches = self.unfold(gx_output)\n",
    "        gy_output_patches = self.unfold(gy_output)\n",
    "\n",
    "        # calculation of variance of each patch\n",
    "        var_target_x = torch.var(gx_target_patches, dim=1)\n",
    "        var_output_x = torch.var(gx_output_patches, dim=1)\n",
    "        var_target_y = torch.var(gy_target_patches, dim=1)\n",
    "        var_output_y = torch.var(gy_output_patches, dim=1)\n",
    "\n",
    "        # loss function as a MSE between variances of patches extracted from gradient maps\n",
    "        gradvar_loss = F.mse_loss(var_target_x, var_output_x) + F.mse_loss(var_target_y, var_output_y)\n",
    "\n",
    "        return gradvar_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
