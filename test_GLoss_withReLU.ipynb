{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from models import SRCNN\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure as SSIM\n",
    "from GLoss import GradientVariance\n",
    "from datasets import TrainDataset, EvalDataset\n",
    "from utils import AverageMeter, calc_psnr, convert_rgb_to_ycbcr, convert_ycbcr_to_rgb\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import PIL.Image as pil_image\n",
    "\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21904 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/399:   0%|          | 0/21904 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 1, 3, 3], expected input[16, 0, 33, 33] to have 1 channels, but got 0 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     79\u001b[0m loss_mse \u001b[38;5;241m=\u001b[39m  criterion(preds, labels)\n\u001b[1;32m---> 80\u001b[0m loss_grad \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradloss_weight \u001b[38;5;241m*\u001b[39m grad_criterion(preds, labels)\n\u001b[0;32m     81\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_mse \u001b[38;5;241m+\u001b[39m loss_grad\n\u001b[0;32m     83\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;28mlen\u001b[39m(inputs))\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\test\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\test\\Desktop\\DLAM-SRCNN\\GLoss.py:30\u001b[0m, in \u001b[0;36mGradientVariance.forward\u001b[1;34m(self, output, target)\u001b[0m\n\u001b[0;32m     27\u001b[0m gray_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2989\u001b[39m \u001b[38;5;241m*\u001b[39m target[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :, :] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5870\u001b[39m \u001b[38;5;241m*\u001b[39m target[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m, :, :] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1140\u001b[39m \u001b[38;5;241m*\u001b[39m target[:, \u001b[38;5;241m2\u001b[39m:, :, :]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# calculation of the gradient maps of x and y directions\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m gx_target \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(gray_target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_x, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m gy_target \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(gray_target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_y, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m gx_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(gray_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_x, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 3, 3], expected input[16, 0, 33, 33] to have 1 channels, but got 0 channels instead"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train-file', type=str, required=True)\n",
    "parser.add_argument('--eval-file', type=str, required=True)\n",
    "parser.add_argument('--outputs-dir', type=str, required=True)\n",
    "parser.add_argument('--scale', type=int, default=3)\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--batch-size', type=int, default=16)\n",
    "parser.add_argument('--num-epochs', type=int, default=400)\n",
    "parser.add_argument('--num-workers', type=int, default=8)\n",
    "parser.add_argument('--seed', type=int, default=123)\n",
    "parser.add_argument('--loss-patch-size', type=int, default=3) \n",
    "parser.add_argument('--gradloss-weight', type=float, default=1.0)\n",
    "\n",
    "args = parser.parse_args([\n",
    "    '--train-file', 'data/91-image_x2.h5',\n",
    "    '--eval-file', 'data/Set5_x2.h5',\n",
    "    '--outputs-dir', 'weights/SRCNN_GELU_x2',\n",
    "    '--scale', '2',\n",
    "    '--lr', '0.0001',\n",
    "    '--batch-size', '16',\n",
    "    '--num-epochs', '400',\n",
    "    '--num-workers', '8',\n",
    "    '--seed', '123',\n",
    "    '--loss-patch-size', '8'\n",
    "])\n",
    "\n",
    "args.outputs_dir = os.path.join(args.outputs_dir, 'x{}'.format(args.scale))\n",
    "\n",
    "if not os.path.exists(args.outputs_dir):\n",
    "    os.makedirs(args.outputs_dir)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "model = SRCNN().to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = SSIM(data_range=1.0).to(device)\n",
    "grad_criterion = GradientVariance(patch_size=args.loss_patch_size, cpu=True).to(device)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.conv1.parameters()},\n",
    "    {'params': model.conv2.parameters()},\n",
    "    {'params': model.conv3.parameters(), 'lr': args.lr * 0.1}\n",
    "], lr=args.lr)\n",
    "\n",
    "train_dataset = TrainDataset(args.train_file)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=args.batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=args.num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "eval_dataset = EvalDataset(args.eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % args.batch_size)) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, args.num_epochs - 1))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            loss_mse =  criterion(preds, labels)\n",
    "            loss_grad = args.gradloss_weight * grad_criterion(preds, labels)\n",
    "            loss = loss_mse + loss_grad\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            preds = model(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(args.outputs_dir, 'best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--weights-file', type=str, required=True)\n",
    "parser.add_argument('--image-file', type=str, required=True)\n",
    "parser.add_argument('--scale-down', type=bool, default=False)\n",
    "parser.add_argument('--scale', type=int, default=3)\n",
    "args = parser.parse_args([\n",
    "    '--weights-file', 'weights/SRCNN_GLoss_x2/best.pth',\n",
    "    '--image-file', 'data/butterfly_GT.bmp',\n",
    "    '--scale-down', 'False',\n",
    "    '--scale', '2'\n",
    "])\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SRCNN().to(device)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "for n, p in torch.load(args.weights_file, map_location=lambda storage, loc: storage).items():\n",
    "    if n in state_dict.keys():\n",
    "        state_dict[n].copy_(p)\n",
    "    else:\n",
    "        raise KeyError(n)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "image = pil_image.open(args.image_file).convert('RGB')\n",
    "\n",
    "image_width = (image.width // args.scale) * args.scale\n",
    "image_height = (image.height // args.scale) * args.scale\n",
    "image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "if args.scale_down:\n",
    "    image = image.resize((image.width // args.scale, image.height // args.scale), resample=pil_image.BICUBIC)\n",
    "    image = image.resize((image.width * args.scale, image.height * args.scale), resample=pil_image.BICUBIC)\n",
    "    image.save(args.image_file.replace('.', '_bicubic_x{}.'.format(args.scale)))\n",
    "\n",
    "image = np.array(image).astype(np.float32)\n",
    "ycbcr = convert_rgb_to_ycbcr(image)\n",
    "\n",
    "y = ycbcr[..., 0]\n",
    "y /= 255.\n",
    "y = torch.from_numpy(y).to(device)\n",
    "y = y.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = model(y).clamp(0.0, 1.0)\n",
    "\n",
    "psnr = calc_psnr(y, preds)\n",
    "print('PSNR: {:.2f}'.format(psnr))\n",
    "\n",
    "preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "output = pil_image.fromarray(output)\n",
    "output.save(args.image_file.replace('.', '_srcnn_GLoss_x{}.'.format(args.scale)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
